{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18baecef",
   "metadata": {},
   "source": [
    "# A Python Algorithm that extract Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c34004",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import the necessary libraries \n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import bigrams \n",
    "import operator\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f514450",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opening and Reading the file which is the amazon review dataset \n",
    "file = open(file='C:/Users/25822756/Documents/file_new/positive_reviews_of_Video_Games.txt', mode = 'r')\n",
    "lines=file.readlines()\n",
    "## Extracting the Third Column of the Amazon positive Review dataset\n",
    "third_column_of_amazon_review = \" \"\n",
    "for line in lines:\n",
    "    review = line.split('\\t')[2].strip()\n",
    "    third_column_of_amazon_review +=  review \n",
    "third_column_of_amazon_review = third_column_of_amazon_review[:-2]\n",
    "##exporting the Third Column into a New File(review_of_third_column.txt)\n",
    "file = open(file='C:/Users/25822756/Documents/file_new/review_of_third_column.txt', mode= 'w')\n",
    "file.write(third_column_of_amazon_review)\n",
    "file.close()\n",
    "## split the words in the created file into tokens by applying the function word_tokenize\n",
    "Tokenised_word = word_tokenize(third_column_of_amazon_review)\n",
    "## assign  postags to the tokens\n",
    "part_of_speech_tag_word =pos_tag(Tokenised_word)\n",
    "##Generating Bigrams of Part-of-Speech Tags\n",
    "bigrams_part_of_speech_tag_word = list(bigrams(part_of_speech_tag_word ))\n",
    "## Printing Bigrams with it's parts of speech \n",
    "print(bigrams_part_of_speech_tag_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e8c0e",
   "metadata": {},
   "source": [
    "# A Python Algorithm that extract Bigram using Co-occurrence metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tokenizing the third column of Amazon review data\n",
    "Tokenised_word = word_tokenize(third_column_of_amazon_review)\n",
    "part_of_speech_tag_word =pos_tag(Tokenised_word)\n",
    "##Performing part-of-speech tagging on the tokenized words\n",
    "bigrams_part_of_speech_tag_word = list(bigrams(part_of_speech_tag_word ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## computing the function compute_frequency_of_bigrams\n",
    "def compute_frequency_of_bigrams(bigrams_part_of_speech_tag_word):\n",
    "##initializing an empty dictionary for frequency_of_bigram to store the frequency of each bigram \n",
    "    frequency_of_bigram = {}\n",
    "##Extracting words and their different part-of-speech tags from each bigram\n",
    "    for first_element ,second_element in bigrams_part_of_speech_tag_word:\n",
    "        first_word_of_bigram, first_word_of_pos_tag= first_element[0],first_element[1]\n",
    "        second_word_of_bigram, second_word_of_pos_tag = second_element[0], second_element[1]\n",
    "## check if the bigram already exists in the dictionary; if so, increment its frequency count, otherwise initialize the count to 1\n",
    "        if (first_word_of_bigram, second_word_of_bigram) in frequency_of_bigram:\n",
    "            frequency_of_bigram[(first_word_of_bigram, second_word_of_bigram)] += 1\n",
    "        else:\n",
    "            frequency_of_bigram[(first_word_of_bigram, second_word_of_bigram)] = 1\n",
    "##Return the dictionary containing the frequencies of each bigram\n",
    "    return frequency_of_bigram\n",
    "\n",
    "\n",
    "##compute the frequency of the bigram \n",
    "frequency_of_bigram= compute_frequency_of_bigrams(bigrams_part_of_speech_tag_word)\n",
    "## using the itemgetter, sort from decending using the value \n",
    "sort_frequency_of_bigram= dict(sorted(frequency_of_bigram.items(), key=operator.itemgetter(1), reverse = True))\n",
    "## converting to list for slicing to get the top 40 bigrams\n",
    "sorted_frequency_of_bigram= list(sort_frequency_of_bigram.items())[:40]\n",
    "## using for loop to iterate through the top 40 bigrams and print each bigram and its frequency\n",
    "for bigram,frequency in sorted_frequency_of_bigram:\n",
    "    print(bigram,frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f02fc",
   "metadata": {},
   "source": [
    "# A Python Algorithm that extract Bigram Collocation using Co-occurence metric and pos filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting the preprocessing by cleaning the noisy data\n",
    "#Removing the punctuation from the third column of Amazon reviews and converting to lowercase\n",
    "cleaned_third_column_review = third_column_of_amazon_review.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "# Tokenize the cleaned third column review\n",
    "Tokenised_words = word_tokenize(cleaned_third_column_review)\n",
    "\n",
    "## continuing pre-processing by removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "Tokenised_words = [word for word in Tokenised_words if word not in stop_words]\n",
    "\n",
    "# Generate part-of-speech tags and bigrams after preprocessing\n",
    "part_of_speech_tag_word = pos_tag(Tokenised_words)\n",
    "bigrams_part_of_speech_tag_word = list(bigrams(part_of_speech_tag_word))\n",
    "\n",
    "##creating my own frequency of the bigram function instead of using counter\n",
    "##using a tag pattern that excludes words that aren't common phrases by using a combination of verb,noun,adverb  and adjectives.\n",
    "\n",
    "def compute_frequency_bigramse(bigrams_part_of_speech_tag_word):\n",
    "## initializing an empty dictionary frequency_of_bigram to store the frequency of each bigram.\n",
    "    frequency_of_bigram = {}\n",
    "## using a for loop to iterate through each bigram in the input list while extracting the first and second elements along with \n",
    "    for first_element, second_element in bigrams_part_of_speech_tag_word:\n",
    "        first_word_of_bigram, first_word_of_pos_tag = first_element[0], first_element[1]\n",
    "        second_word_of_bigram, second_word_of_pos_tag = second_element[0], second_element[1]\n",
    "##using at if statement that sets a condition that the part-of-speech tags match certain criteria (adjective,noun,verb..), the bigram is considered for frequency calculation.\n",
    "        if first_element[1] == \"JJ\" and second_element[1] == \"NN\":\n",
    "            # Add bigram to frequency_of_bigram dictionary\n",
    "            bigram = (first_word_of_bigram, second_word_of_bigram)\n",
    "## checking if the bigram exists in the frequency_of_bigram dictionary.it increments its frequency count if true; otherwise, it initializes the count to 1.\n",
    "            if bigram in frequency_of_bigram:\n",
    "                frequency_of_bigram[bigram] += 1\n",
    "            else:\n",
    "                frequency_of_bigram[bigram] = 1\n",
    "                \n",
    "        elif first_element[1] == \"NN\" and second_element[1] == \"NN\":\n",
    "            # Add bigram to frequency_of_bigram dictionary\n",
    "            bigram = (first_word_of_bigram, second_word_of_bigram)\n",
    "            if bigram in frequency_of_bigram:\n",
    "                frequency_of_bigram[bigram] += 1\n",
    "            else:\n",
    "                frequency_of_bigram[bigram] = 1\n",
    "                \n",
    "        elif first_element[1] == \"NNP\" and second_element[1] == \"NN\":\n",
    "            # Add bigram to frequency_of_bigram dictionary\n",
    "            bigram = (first_word_of_bigram, second_word_of_bigram)\n",
    "            if bigram in frequency_of_bigram:\n",
    "                frequency_of_bigram[bigram] += 1\n",
    "            else:\n",
    "                frequency_of_bigram[bigram] = 1\n",
    "                \n",
    "        elif first_element[1] == \"NNP\" and second_element[1] == \"NNP\":\n",
    "            # Add bigram to frequency_of_bigram dictionary\n",
    "            bigram = (first_word_of_bigram, second_word_of_bigram)\n",
    "            if bigram in frequency_of_bigram:\n",
    "                frequency_of_bigram[bigram] += 1\n",
    "            else:\n",
    "                frequency_of_bigram[bigram] = 1\n",
    "         \n",
    "        elif first_element[1] == \"RB\" and second_element[1] == \"JJ\":\n",
    "            #Add bigram to frequency_of_bigram dictionary\n",
    "            bigram = (first_word_of_bigram, second_word_of_bigram)\n",
    "            if bigram in frequency_of_bigram:\n",
    "                frequency_of_bigram[bigram] += 1\n",
    "            else:\n",
    "                frequency_of_bigram[bigram] = 1\n",
    "                \n",
    "        elif first_element[1] == \"VB\" and second_element[1] == \"NN\":\n",
    "            # Add bigram to frequency_of_bigram dictionary\n",
    "            bigram = (first_word_of_bigram, second_word_of_bigram)\n",
    "            if bigram in frequency_of_bigram:\n",
    "                frequency_of_bigram[bigram] += 1\n",
    "            else:\n",
    "                frequency_of_bigram[bigram] = 1\n",
    "        else:\n",
    "            pass\n",
    "    ## return the frequency_of_bigram              \n",
    "    return frequency_of_bigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec164950",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating the frequecy of the bigram with postag by using the function compute_frequency_bigramse\n",
    "frequency_of_bigram_three= compute_frequency_bigramse(bigrams_part_of_speech_tag_word)\n",
    "##sorting the bigram by using sort,itemgetter method \n",
    "sort_frequency_of_bigram= dict(sorted(frequency_of_bigram_three.items(), key=operator.itemgetter(1), reverse = True))\n",
    "# changing the dict to list for easy slicing \n",
    "sorted_new_frequency_of_bigram= list(sort_frequency_of_bigram.items())[:40]\n",
    "## using a for loop to iterate over the sorted_new_frequency_of_bigram to print each bigram and the number of time it is counted\n",
    "for bigram,frequency in sorted_new_frequency_of_bigram:\n",
    "    print(bigram,frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a538f4f8",
   "metadata": {},
   "source": [
    "# A Python Algorithm that extract Bigram Collocation using the Point-wise Mutual Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33396fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting the preprocessing by cleaning the noisy data\n",
    "punctuation_to_remove = \"-/.\"  \n",
    "\n",
    "# Creating a translation table where the specified punctuation marks are replaced with None\n",
    "translation_table = str.maketrans(punctuation_to_remove, \" \" * len(punctuation_to_remove))\n",
    "\n",
    "# Applying the translation table to remove the specified punctuation marks\n",
    "cleaned_third_column_of_amazon_review = third_column_of_amazon_review.translate(translation_table)\n",
    "\n",
    "## Tokenizing the cleaned third column review\n",
    "Tokenised_words = word_tokenize(cleaned_third_column_of_amazon_review)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "Tokenised_words = [' ' if word in stop_words else word for word in Tokenised_words]\n",
    "\n",
    "## Generate part-of-speech tags and bigrams after preprocessing\n",
    "part_of_speech_tag_word = pos_tag(Tokenised_words)\n",
    "bigrams_part_of_speech_tag_word = list(bigrams(part_of_speech_tag_word))\n",
    "\n",
    "\n",
    "##Computing the function frequency of bigrams from a list of bigrams passing the arg* bigrams_part_of_speech_tag_word to return the frequecy count of each bigrams\n",
    "def compute_frequency_of_bigrams(bigrams_part_of_speech_tag_word):\n",
    "    frequency_of_bigram = {}\n",
    "    for first_element, second_element in bigrams_part_of_speech_tag_word:\n",
    "        first_word_of_bigram, first_word_of_pos_tag = first_element[0], first_element[1]\n",
    "        second_word_of_bigram, second_word_of_pos_tag = second_element[0], second_element[1]\n",
    "        if (first_word_of_bigram, second_word_of_bigram) in frequency_of_bigram:\n",
    "            frequency_of_bigram[(first_word_of_bigram, second_word_of_bigram)] += 1\n",
    "        else:\n",
    "            frequency_of_bigram[(first_word_of_bigram, second_word_of_bigram)] = 1\n",
    "    return frequency_of_bigram\n",
    "\n",
    "\n",
    "\n",
    "## Count frequencies of individual words and bigrams\n",
    "word_counts = {}\n",
    "for word in Tokenised_words:\n",
    "    if word in word_counts:\n",
    "        word_counts[word] += 1\n",
    "    else:\n",
    "        word_counts[word] = 1\n",
    "\n",
    "# compute the frequecy of the bigram by applying the compute_frequency function\n",
    "bigram_counts = compute_frequency_of_bigrams(bigrams_part_of_speech_tag_word)\n",
    "\n",
    "\n",
    "# Total number of words in the corpus\n",
    "N = len(Tokenised_words)\n",
    "\n",
    "## Calculate PMI for each bigram\n",
    "pmi_scores = {}\n",
    "for bigram in bigram_counts:\n",
    "    first_word, second_word = bigram\n",
    "    frequency_of_bigram = bigram_counts[bigram]\n",
    "    frequency_of_first_word = word_counts[first_word]\n",
    "    frequency_of_second_word = word_counts[second_word]\n",
    "\n",
    "## Calculating probabilities\n",
    "    probability_of_bigram = frequency_of_bigram / N\n",
    "    probability_of_first_word = frequency_of_first_word / N\n",
    "    probability_of_second_word = frequency_of_second_word / N\n",
    "\n",
    "## Calculating PMI   \n",
    "    pmi = math.log(probability_of_bigram / (probability_of_first_word * probability_of_second_word), 2.0)\n",
    "    \n",
    "    pmi_scores[bigram] = pmi\n",
    "\n",
    "## Sorting PMI scores by value (PMI score) in descending order\n",
    "sorted_pmi_scores = sorted(pmi_scores.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "## extracting the top 40 PMI scores in descending order by slicing and iterating over the score \n",
    "top_40_pmi_scores = sorted_pmi_scores[:40]\n",
    "for i, (bigram, pmi) in enumerate(top_40_pmi_scores, 1):\n",
    "    print(f\"{i}. PMI for {bigram}: {pmi}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
